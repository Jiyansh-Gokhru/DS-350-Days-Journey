# Day 32 — Bias–Variance Tradeoff

## Objective
To understand why machine learning models underfit or overfit and how bias and variance affect model performance.

---

## Key Concepts

### Bias
- Error due to overly simple models
- Leads to underfitting
- High training and test error

### Variance
- Error due to overly complex models
- Leads to overfitting
- Low training error, high test error

---

## Bias–Variance Tradeoff
Reducucing bias often increases variance, and reducing variance often increases bias.  
The goal is to find a balance where the model performs well on unseen data.

---

## Practical Demonstration
- Linear Regression → Underfitting (High Bias)
- High-degree Polynomial Regression → Overfitting (High Variance)

The best model lies between these extremes.

---

## Interview Takeaway
“A good machine learning model is one that generalizes well, not one that memorizes the training data.”
