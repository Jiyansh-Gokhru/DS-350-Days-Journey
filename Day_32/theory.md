# Bias–Variance Tradeoff

## Bias
Bias is the error caused when a model is **too simple** to capture the real pattern in data.  
A high-bias model makes strong assumptions and ignores important relationships.

## Variance
Variance is the error caused when a model is **too complex** and reacts too much to small changes in the training data.  
A high-variance model memorizes data instead of learning general patterns.

## Underfitting
Underfitting happens when a model is **too simple** and performs poorly on both training and test data.

**Real-life example:**  
Trying to predict house prices using only the number of rooms, while ignoring location, size, and condition.

## Overfitting
Overfitting happens when a model learns the **training data too well**, including noise, and performs poorly on new data.

**Real-life example:**  
Memorizing answers for a specific question paper instead of understanding the concepts.

## Bias–Variance Tradeoff
Reducing bias usually increases variance, and reducing variance usually increases bias.  
The goal is to find a balance where the model generalizes well to unseen data.
